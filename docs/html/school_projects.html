<!DOCTYPE html>
<html>
    <meta charset="UTF-8">
    <head>
        <title>Mateo Topete Portfolio</title>
        <link rel="stylesheet" href="../style.css">
        <link rel="icon" href="../resources/images/hrm.jpg">
    </head>
<h1 class = 'title'>College Coursework</h1>

<nav>
    <ul>
        <li><a href="../index.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="#">Portfolio</a>
        <ul>
            <li><a href="personal_projects.html">Personal-projects</a></li>
            <li><a href="school_projects.html">School-projects</a></li>
        </ul>
        </li>
        <li><a href="certifications.html">Certifications</a>
        </li>
    </ul>
    <ul style="float:right">
        <li><a href="https://www.linkedin.com/in/mateo-topete-a29607173/" target="_blank">LinkedIn</a></li>
        <li><a href="https://github.com/mttopete" target="_blank">Github</a></li>
    </ul>
</nav>
<proj-body>
    <div>
        <h2>Minecraft Lumberjack AI
            <br>
            <small>A course-long group project to design an AI using reinforcement learning in the <a href = 'https://www.microsoft.com/en-us/research/project/project-malmo/' target ='_blank' title = 'https://www.microsoft.com/en-us/research/project/project-malmo/'>Microsoft MALMO enviorment.</a></small>
        </h2>
        <h3>Goal</h3>
        <p>
            Worked on in a groups of 3-4, we were tasked with researching and developing an agent to preform a task using reinforcement learning.
            Our group chose to train an agent in Minecraft using Microsoft's MALMO project for reinforcement learning in Minecraft with the goal of
            having it learn to chop down as many trees as it could in a set period of time while avoiding pitfalls and managing its resources.
        </p>
        <h3>Technologies Used</h3>
        <ul>
            <li><a href = 'https://www.microsoft.com/en-us/research/project/project-malmo/' target ='_blank' title = 'https://www.microsoft.com/en-us/research/project/project-malmo/'>Microsoft MALMO environment.</a>
                for integrated access to the Minecraft environment through an agent.
            </li>
            <li><a href = 'https://docs.ray.io/en/latest/rllib/index.html' target = '_blank' title = 'https://docs.ray.io/en/latest/rllib/index.html'>RLlib</a>
                for reinforcement learning algorithms, specifically the
                <a href = 'https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#sac' target = '_blank' title = 'https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#sac'>SAC</a> 
                implementation.  Chosen for its ability to take a continuous action space as input as well as apply convolutions to multi-dimensional observations.
            </li>
            <li> <a href = 'https://www.gymlibrary.dev' target="_blank" title = 'https://www.gymlibrary.dev'>Gym</a>
                for environment observation and rewarding the agent, as well as being able to generate a continuous action space
            </li>
            <li>Numpy</li>
            <li>MatplotLib</li>
        </ul>
        <h3>Results</h3>
        <p>
            We received a B+ on our project, mostly attributed to a poor write-up and explanation of our results.<br>
            The agent never managed to preform as well as we would have liked, although at the time we could not figure out exactly what the problem was.
            If left for a long period of time the agent would prefer to spin in place as if refusing to work; something we figured was a problem in our reward definitions.
            Additionally, while the convolutions did help the performance and vision of the model, i believe we failed to properly define them.
            <br><br>
            A year or so after this project while doing my own projects/research into computer vision i went back to the code and saw that we defined the convolutions abysmally.
            In hindsight, we should have looked for practical implementation and examples of them rather than trying to brute-force our way through the textbook and academic texts
            to figure out how to properly apply them to our problem. Going back to the project, i can easily see where we could make improvements.
            <br><br>
        </p>
    </div>
    <div>
        <h2>Web Scraper and Search Engine<br>
            <small>
                A two-part course-long project consisting of a Web Scraper to create an index for use in a Search Engine
            </small>
        </h2>
        <h3>Technologies Used</h3>
        <ul>
            <li>School-provided initial <a href = 'https://github.com/Mondego/spacetime-crawler4py' target = '_blank' title = 'https://github.com/Mondego/spacetime-crawler4py'>code</a>
            - contained a launch file, basic utility libraries, and skeleton code to be filled in and augmented by the students
            </li>
            <li><a href = 'https://www.crummy.com/software/BeautifulSoup/bs4/doc/' target = '_blank' title="BeautifulSoup">Beautiful Soup</a> to parse webpage html</li>
            <li>Python urllib for handling urls</li>
            <li>Python Regular Expressions</li>
            <li>Multi-threading in python</li>
        </ul>
        <h3>Constraints</h3>
        <p>
            The implementation of the Web Crawler, its resulting Index and the Search Engine was open-ended as far as creativity for the code
            so long as it followed the following requirements:
        </p>
        <h3>The Web Crawler</h3>
        <ul>
            <li>Must be 'polite' - at least 500ms between request to the same domain</li>
            <li>Avoid infinite traps</li>
            <li>Avoid similar pages with little or no new information</li>
            <li>Detect and avoid dead urls</li>
            <li>Detect and avoid crawling very large files</li>
            <li>Extra credit: multi-threaded and detect/avoid similar webpages</li>
        </ul>
        <h3>The Index</h3>
        <ul>
            <li>Must be stored as an inverted index</li>
            <li>Index must be stored as a file, not in a database</li>
            <li>Postings in the index must account for the importance of the word's appearance (bold/heading/title)</li>
            <li>The entire index must not be held in memory at once</li>
            <li>The index must be offloaded from memory into parts and reconstructed as one or more files at the end without ever loading all parts at once</li>
        </ul>
        <h3>The Search Engine</h3>
            <ul>
                <li>Must have below a 300ms response time</li>
                <li>The Index must also never be loaded in its entirety</li>
                <li>Results must have some ranking to them (tf-idf + importance minimum)</li>
            </ul>
        <h3>Results</h3>
        <p>I received an A on the project, with a slight deduction in points due to un-optimized code in the search engine. The response time however still
            fell within the acceptable range of 300ms or below. The final submission successfully met all of the above constraints including the extra credit
            for the web crawler portion. The crawler was released on an internal server to ensure that students did not impact public services with buggy code
            and the total amount of web pages crawled numbered well over 50,000; all of which were parsed, stemmed, tokenized, scored, and indexed into a file
            and used in a search engine capable of returning relevant results in under 300ms.
        </p>
    <br>
    <h2>Minor projects</h2>
    <h3>Food/Point of Interest 'Bot'</h3>
    <p>
        An exercise in making requests from API's and introductory Natural Language Processing.
        It was created to parse sentences for key words related to a questions being asked about locations of restaurants.
        Due to using the MapQuest api for location searching and direction giving, it ended up able to provide information and directions to anywhere
        that mapquest had available even if a non food related location was asked of it.
    </p>
    <h3>Movie Manager</h3>
    <p>An exercise in c++ file and class structures. Lets users keep track of a movie inventory and renters of those movies</p>
    <br><br><br><br>
    </div>
    <div>
        <p>I couldn't get pictures/demonstrations of school projects due to environments/resources being stored on or deleted from school servers, outdated API keys, and deprecated code.</p>
    </div>
</proj-body>
<br><br><br><br><br><br><br><br><br><br><br><br>

</html>